{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing modules\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, make_scorer\n",
    "import warnings\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "warnings.filterwarnings('ignore')\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import make_pipeline as make_pipeline_imb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the datasets\n",
    "df_train = pd.read_csv('../data/training.csv', index_col=0)\n",
    "\n",
    "X_train = df_train['article_words'].values\n",
    "y_train = df_train['topic'].values\n",
    "\n",
    "assert(len(X_train) == 9500)\n",
    "assert(len(y_train) == 9500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = set(y_train)\n",
    "labels.remove('IRRELEVANT')\n",
    "custom_f1 = make_scorer(f1_score, labels=list(labels), average='macro')\n",
    "\n",
    "scorer = {\n",
    "    'accuracy': 'accuracy',\n",
    "    'precision': make_scorer(precision_score, labels=list(labels), average='micro'),\n",
    "    'recall': make_scorer(recall_score, labels=list(labels), average='micro'),\n",
    "    'f1': make_scorer(f1_score, labels=list(labels), average='micro'),    \n",
    "    'precision_macro': make_scorer(precision_score, labels=list(labels), average='macro'),\n",
    "    'recall_macro': make_scorer(recall_score, labels=list(labels), average='macro'),\n",
    "    'f1_macro': make_scorer(f1_score, labels=list(labels), average='macro'),\n",
    "    'custom': custom_f1,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = make_pipeline_imb(\n",
    "    TfidfVectorizer(),\n",
    "    SMOTE(random_state=0,n_jobs=-1),\n",
    "    DecisionTreeClassifier( criterion='gini',random_state=0, min_samples_split = 15)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "parameters = {\n",
    "    \n",
    "    'tfidfvectorizer__max_features': [20_000],\n",
    "    'tfidfvectorizer__max_df': [0.5],\n",
    "    'tfidfvectorizer__sublinear_tf': (True, False),\n",
    "    'tfidfvectorizer__lowercase': (True, False),\n",
    "    'decisiontreeclassifier__min_samples_leaf':[10,12,15,20],\n",
    "    'decisiontreeclassifier__min_samples_split':[2,4,6],\n",
    "    'decisiontreeclassifier__splitter':('best', 'random')\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 96 candidates, totalling 288 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:  4.6min\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed: 22.8min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed: 53.7min\n",
      "[Parallel(n_jobs=-1)]: Done 280 tasks      | elapsed: 86.0min\n",
      "[Parallel(n_jobs=-1)]: Done 288 out of 288 | elapsed: 87.7min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('tfidfvectorizer',\n",
       "                                        TfidfVectorizer(analyzer='word',\n",
       "                                                        binary=False,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.float64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=True,\n",
       "                                                        max_df=1.0,\n",
       "                                                        max_features=None,\n",
       "                                                        min_df=1,\n",
       "                                                        ngram_range=(1, 1),\n",
       "                                                        norm='l2',\n",
       "                                                        preprocessor=None,\n",
       "                                                        smooth_idf=True,\n",
       "                                                        stop_words=None...\n",
       "                      'recall': make_scorer(recall_score, labels=['ARTS CULTURE ENTERTAINMENT', 'SPORTS', 'DEFENCE', 'FOREX MARKETS', 'MONEY MARKETS', 'HEALTH', 'SCIENCE AND TECHNOLOGY', 'DOMESTIC MARKETS', 'BIOGRAPHIES PERSONALITIES PEOPLE', 'SHARE LISTINGS'], average=micro),\n",
       "                      'recall_macro': make_scorer(recall_score, labels=['ARTS CULTURE ENTERTAINMENT', 'SPORTS', 'DEFENCE', 'FOREX MARKETS', 'MONEY MARKETS', 'HEALTH', 'SCIENCE AND TECHNOLOGY', 'DOMESTIC MARKETS', 'BIOGRAPHIES PERSONALITIES PEOPLE', 'SHARE LISTINGS'], average=macro)},\n",
       "             verbose=5)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_clf = GridSearchCV(clf, \n",
    "                     parameters, \n",
    "                     cv=3, \n",
    "                     n_jobs=-1, \n",
    "                     verbose = 5, \n",
    "                     scoring=scorer, \n",
    "                     refit='custom', \n",
    "                     return_train_score=True)\n",
    "\n",
    "gs_clf.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best cross-validation score: 0.48\n",
      "Best params: {'decisiontreeclassifier__min_samples_leaf': 15, 'decisiontreeclassifier__min_samples_split': 2, 'decisiontreeclassifier__splitter': 'best', 'tfidfvectorizer__lowercase': True, 'tfidfvectorizer__max_df': 0.5, 'tfidfvectorizer__max_features': 20000, 'tfidfvectorizer__sublinear_tf': False}\n"
     ]
    }
   ],
   "source": [
    "print(f'Best cross-validation score: {gs_clf.best_score_:.2f}')\n",
    "print(f'Best params: {gs_clf.best_params_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Refitting the best estimatory by grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('tfidfvectorizer',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=0.5, max_features=20000,\n",
       "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 sublinear_tf=False,\n",
       "                                 toke...\n",
       "                       sampling_strategy='auto', svm_estimator='deprecated')),\n",
       "                ('decisiontreeclassifier',\n",
       "                 DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None,\n",
       "                                        criterion='gini', max_depth=None,\n",
       "                                        max_features=None, max_leaf_nodes=None,\n",
       "                                        min_impurity_decrease=0.0,\n",
       "                                        min_impurity_split=None,\n",
       "                                        min_samples_leaf=15,\n",
       "                                        min_samples_split=2,\n",
       "                                        min_weight_fraction_leaf=0.0,\n",
       "                                        presort='deprecated', random_state=0,\n",
       "                                        splitter='best'))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_clf = gs_clf.best_estimator_\n",
    "best_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the results to a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>mean_train_accuracy</th>\n",
       "      <th>std_train_accuracy</th>\n",
       "      <th>mean_test_accuracy</th>\n",
       "      <th>std_test_accuracy</th>\n",
       "      <th>mean_train_precision</th>\n",
       "      <th>std_train_precision</th>\n",
       "      <th>mean_test_precision</th>\n",
       "      <th>std_test_precision</th>\n",
       "      <th>mean_train_recall</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_recall_macro</th>\n",
       "      <th>std_test_recall_macro</th>\n",
       "      <th>mean_train_f1_macro</th>\n",
       "      <th>std_train_f1_macro</th>\n",
       "      <th>mean_test_f1_macro</th>\n",
       "      <th>std_test_f1_macro</th>\n",
       "      <th>mean_train_custom</th>\n",
       "      <th>std_train_custom</th>\n",
       "      <th>mean_test_custom</th>\n",
       "      <th>std_test_custom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>decision_tree</td>\n",
       "      <td>0.779736</td>\n",
       "      <td>0.00795</td>\n",
       "      <td>0.657263</td>\n",
       "      <td>0.003263</td>\n",
       "      <td>0.696194</td>\n",
       "      <td>0.006954</td>\n",
       "      <td>0.531755</td>\n",
       "      <td>0.005636</td>\n",
       "      <td>0.820184</td>\n",
       "      <td>...</td>\n",
       "      <td>0.56114</td>\n",
       "      <td>0.010307</td>\n",
       "      <td>0.694542</td>\n",
       "      <td>0.010679</td>\n",
       "      <td>0.481532</td>\n",
       "      <td>0.00229</td>\n",
       "      <td>0.694542</td>\n",
       "      <td>0.010679</td>\n",
       "      <td>0.481532</td>\n",
       "      <td>0.00229</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           model  mean_train_accuracy  std_train_accuracy  mean_test_accuracy  \\\n",
       "0  decision_tree             0.779736             0.00795            0.657263   \n",
       "\n",
       "   std_test_accuracy  mean_train_precision  std_train_precision  \\\n",
       "0           0.003263              0.696194             0.006954   \n",
       "\n",
       "   mean_test_precision  std_test_precision  mean_train_recall  ...  \\\n",
       "0             0.531755            0.005636           0.820184  ...   \n",
       "\n",
       "   mean_test_recall_macro  std_test_recall_macro  mean_train_f1_macro  \\\n",
       "0                 0.56114               0.010307             0.694542   \n",
       "\n",
       "   std_train_f1_macro  mean_test_f1_macro  std_test_f1_macro  \\\n",
       "0            0.010679            0.481532            0.00229   \n",
       "\n",
       "   mean_train_custom  std_train_custom  mean_test_custom  std_test_custom  \n",
       "0           0.694542          0.010679          0.481532          0.00229  \n",
       "\n",
       "[1 rows x 33 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "model_name ='decision_tree'\n",
    "\n",
    "best_idx = gs_clf.cv_results_['params'].index(gs_clf.best_params_)\n",
    "\n",
    "d = {\n",
    "    'model': model_name,\n",
    "}\n",
    "\n",
    "for metric in scorer:\n",
    "    for dataset in ['train', 'test']:\n",
    "        for stat in ['mean', 'std']:\n",
    "            metric_item = f'{stat}_{dataset}_{metric}'\n",
    "            d[metric_item] = gs_clf.cv_results_[metric_item][best_idx]\n",
    "\n",
    "df_models_clf = pd.DataFrame(d, index=[0])\n",
    "\n",
    "with open(f'/Users/ashish/Desktop/UNSW/COMP9417/Project/COMP9417-project/data/pickles/best_{model_name}.pickle', 'wb') as output:\n",
    "    pickle.dump(best_clf, output)\n",
    "    \n",
    "with open(f'/Users/ashish/Desktop/UNSW/COMP9417/Project/COMP9417-project/data/pickles/df_results_{model_name}.pickle', 'wb') as output:\n",
    "    pickle.dump(df_models_clf, output)\n",
    "    \n",
    "df_models_clf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
